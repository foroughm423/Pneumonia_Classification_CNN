{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Detection on Chest X-Rays with CNN (TensorFlow/Keras)\n",
        "\n",
        "_End-to-end training and evaluation with accuracy/loss curves, confusion matrix, ROC, misclassified cases, and best model (.keras)._\n",
        "\n",
        "**Task:** Binary classification (Normal vs Pneumonia)  \n",
        "**Framework:** TensorFlow/Keras  \n",
        "**Dataset:** Chest X-Ray Images (Pneumonia) (Kermany et al., via Kaggle)\n"
      ],
      "metadata": {
        "id": "Wu4j1TGhc0I4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "# General-purpose\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "# Deep learning (TensorFlow & Keras)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import (Dense, Conv2D, MaxPooling2D, Flatten, Dropout,\n",
        "                                     BatchNormalization, GlobalAveragePooling2D, Input)\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Evaluation (scikit-learn)\n",
        "from sklearn.metrics import (classification_report, confusion_matrix,\n",
        "                             ConfusionMatrixDisplay, roc_auc_score, roc_curve, auc)\n",
        "\n",
        "# Set seeds\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "Ux0VRQTjq_yU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip Chest X-Ray Pneumonia dataset\n",
        "\n",
        "# Install Kaggle API\n",
        "# !pip install -q kaggle\n",
        "\n",
        "# If running locally or in Colab, upload your kaggle.json here:\n",
        "# from google.colab import files\n",
        "# files.upload()  # Upload kaggle.json manually\n",
        "\n",
        "# Or manually place kaggle.json in ~/.kaggle/\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "# os.rename('kaggle.json', '/root/.kaggle/kaggle.json')  # Uncomment if using upload method\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "\n",
        "# Download and unzip the dataset\n",
        "# !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "# !unzip -q chest-xray-pneumonia.zip -d ./pneumonia_data\n",
        "\n",
        "# NOTE: For manual setup (e.g., GitHub), place the dataset manually in:\n",
        "# ./pneumonia_data/chest_xray\n",
        "# Dataset link: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "id": "QUluOdROu72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a sample image from each class\n",
        "\n",
        "train_dir = './pneumonia_data/chest_xray/train'\n",
        "classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, label in enumerate(classes):\n",
        "    class_dir = os.path.join(train_dir, label)\n",
        "    image_file = random.choice(os.listdir(class_dir))\n",
        "    image_path = os.path.join(class_dir, image_file)\n",
        "\n",
        "    img = mpimg.imread(image_path)\n",
        "\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(label)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cjvNTpiHu3fE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing with better augmentation and internal validation split\n",
        "\n",
        "# Image parameters\n",
        "img_size = (150, 150)\n",
        "batch_size = 16\n",
        "\n",
        "# Data augmentation for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=1,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.99, 1.01],\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # 20% of training data for validation\n",
        ")\n",
        "\n",
        "# Train generator (80% of train directory)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/pneumonia_data/chest_xray/train',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='binary',\n",
        "    subset='training',\n",
        "    shuffle=True,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Validation generator (20% of train directory)\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    '/content/pneumonia_data/chest_xray/train',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='binary',\n",
        "    subset='validation',\n",
        "    shuffle=False,\n",
        "    seed=42\n",
        ")\n",
        "\n",
        "# Test generator (unchanged - only rescaling, no augmentation)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    '/content/pneumonia_data/chest_xray/test',\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    color_mode='grayscale',\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Train samples:\", train_generator.samples)\n",
        "print(\"Validation samples:\", val_generator.samples)\n",
        "print(\"Test samples:\", test_generator.samples)"
      ],
      "metadata": {
        "id": "j2i7CERpvMxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a simple CNN model using Keras\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Dropout(0.8))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.005)))\n",
        "model.add(Dropout(0.8))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ykpilqWmvTL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "learning_rate = 0.00025\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=learning_rate),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "msMeGRFJvYVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "\n",
        "checkpoint_path = 'best_model.keras'\n",
        "\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=4,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "lr_scheduler = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.4,\n",
        "    patience=2,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    checkpoint_path,\n",
        "    monitor='val_accuracy',\n",
        "    save_best_only=True,\n",
        "    mode='max',\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=[checkpoint, early_stopping, lr_scheduler],\n",
        "    class_weight = {0: 1.0, 1: 0.86}\n",
        ")\n",
        "\n",
        "# files.download(checkpoint_path)"
      ],
      "metadata": {
        "id": "i0qhoxtIvccu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy and loss\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PuximOWNvg6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test data\n",
        "\n",
        "y_pred_prob = model.predict(test_generator)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "y_true = test_generator.classes\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zcnnKL9vvl4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC Curve and AUC for test data\n",
        "\n",
        "# Compute ROC curve and AUC\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_pred_prob)\n",
        "roc_auc = roc_auc_score(y_true, y_pred_prob)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_0z4FEHPu1BM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some misclassified test images\n",
        "\n",
        "misclassified_idx = np.where(y_true != y_pred.flatten())[0]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i, idx in enumerate(misclassified_idx[:6]):\n",
        "    img_path = test_generator.filepaths[idx]\n",
        "    img = mpimg.imread(img_path)\n",
        "\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    true_label = 'NORMAL' if y_true[idx] == 0 else 'PNEUMONIA'\n",
        "    pred_label = 'NORMAL' if y_pred[idx] == 0 else 'PNEUMONIA'\n",
        "    plt.title(f'True: {true_label}\\nPred: {pred_label}')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5NiN-QVNvbfB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}