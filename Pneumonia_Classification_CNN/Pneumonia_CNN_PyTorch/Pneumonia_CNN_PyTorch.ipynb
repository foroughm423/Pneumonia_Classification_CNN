{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pneumonia Detection on Chest X-Rays with CNN (PyTorch)\n",
        "\n",
        "_Complete PyTorch pipeline with training loop, accuracy/loss curves, confusion matrix, ROC, misclassified cases, and best model (.pth)._\n",
        "\n",
        "**Task:** Binary classification (Normal vs Pneumonia)  \n",
        "**Framework:** PyTorch  \n",
        "**Dataset:** Chest X-Ray Images (Pneumonia) (Kermany et al., via Kaggle)\n"
      ],
      "metadata": {
        "id": "2X3px4MkdFNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports & Reproducibility\n",
        "\n",
        "# General-purpose\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "\n",
        "# Deep learning (PyTorch)\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "# Evaluation (scikit-learn)\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, ConfusionMatrixDisplay,\n",
        "    roc_curve, roc_auc_score\n",
        ")\n",
        "\n",
        "# Reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# deterministic cuDNN for reproducibility\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(\"Device:\", device)"
      ],
      "metadata": {
        "id": "L0oC3ltNmWDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download and unzip Chest X-Ray Pneumonia dataset\n",
        "\n",
        "# Install Kaggle API\n",
        "# !pip install -q kaggle\n",
        "\n",
        "# If running locally or in Colab, upload your kaggle.json here:\n",
        "# from google.colab import files\n",
        "# files.upload()  # Upload kaggle.json manually\n",
        "\n",
        "# Or manually place kaggle.json in ~/.kaggle/\n",
        "os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "# os.rename('kaggle.json', '/root/.kaggle/kaggle.json')  # Uncomment if using upload method\n",
        "os.chmod('/root/.kaggle/kaggle.json', 600)\n",
        "\n",
        "# Download and unzip the dataset\n",
        "# !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia\n",
        "# !unzip -q chest-xray-pneumonia.zip -d ./pneumonia_data\n",
        "\n",
        "# NOTE: For manual setup (e.g., GitHub), place the dataset manually in:\n",
        "# ./pneumonia_data/chest_xray\n",
        "# Dataset link: https://www.kaggle.com/paultimothymooney/chest-xray-pneumonia"
      ],
      "metadata": {
        "id": "xBIewJDlmfFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize a sample image from each class\n",
        "\n",
        "train_dir = '/content/pneumonia_data/chest_xray/train'\n",
        "classes = ['NORMAL', 'PNEUMONIA']\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "for i, label in enumerate(classes):\n",
        "    class_dir = os.path.join(train_dir, label)\n",
        "    image_file = random.choice(os.listdir(class_dir))\n",
        "    image_path = os.path.join(class_dir, image_file)\n",
        "\n",
        "    img = mpimg.imread(image_path)\n",
        "    plt.subplot(1, 2, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(label)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZhMKEuO-mjXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing with augmentation + internal validation split\n",
        "\n",
        "# Image parameters\n",
        "img_size = (150, 150)\n",
        "batch_size = 16\n",
        "\n",
        "# Data augmentation transforms\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=1, fill=0),\n",
        "    transforms.RandomAffine(\n",
        "        degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10, fill=0\n",
        "    ),\n",
        "    transforms.ColorJitter(brightness=(0.99, 1.01)),\n",
        "    transforms.ToTensor(),  # scales to [0,1]\n",
        "])\n",
        "\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(img_size),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Load full training folder with augmentations\n",
        "full_train = datasets.ImageFolder(root=os.path.join('/content/pneumonia_data', 'chest_xray', 'train'),\n",
        "                                  transform=train_transforms)\n",
        "\n",
        "# Split into train/val (80/20) with fixed seed\n",
        "dataset_size = len(full_train)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "generator = torch.Generator().manual_seed(42)\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(\n",
        "    full_train, [train_size, val_size], generator=generator\n",
        ")\n",
        "\n",
        "# Apply validation transforms to the underlying dataset for val split\n",
        "val_dataset.dataset.transform = val_test_transforms  # ensure no augmentation in val\n",
        "\n",
        "# Test dataset\n",
        "test_dataset = datasets.ImageFolder(root=os.path.join('/content/pneumonia_data', 'chest_xray', 'test'),\n",
        "                                    transform=val_test_transforms)\n",
        "\n",
        "# DataLoaders\n",
        "num_workers = 2\n",
        "pin_memory = torch.cuda.is_available()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                          drop_last=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False,\n",
        "                          drop_last=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False,\n",
        "                          drop_last=False, num_workers=num_workers, pin_memory=pin_memory)\n",
        "\n",
        "print(\"Class to idx mapping:\", full_train.class_to_idx)  # expect {'NORMAL':0, 'PNEUMONIA':1}\n",
        "print(\"Train samples:\", len(train_dataset))\n",
        "print(\"Validation samples:\", len(val_dataset))\n",
        "print(\"Test samples:\", len(test_dataset))"
      ],
      "metadata": {
        "id": "efY8piKimmvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN model (BCEWithLogitsLoss-ready)\n",
        "class PneumoniaCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 3, padding=1), nn.BatchNorm2d(32), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(), nn.MaxPool2d(2),\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.8),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(256*9*9, 128), nn.ReLU(),\n",
        "            nn.Dropout(0.8),\n",
        "            nn.Linear(128, 1) # logits\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = PneumoniaCNN()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "# print(model)"
      ],
      "metadata": {
        "id": "FskqP1wFmqdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss, Optimizer, Scheduler setup\n",
        "learning_rate = 0.00025\n",
        "# Use BCEWithLogitsLoss (more stable than BCE + Sigmoid inside model)\n",
        "pos_weight = torch.tensor([0.77], device=device) # Adjusted to 0.77 to fine-tune balance\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.005)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.4, patience=2, min_lr=1e-6)\n",
        "print('Optimizer/Loss ready.')"
      ],
      "metadata": {
        "id": "59IQ356gmu7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop with early stopping & checkpoint\n",
        "\n",
        "checkpoint_path = 'best_model_pytorch.pth'\n",
        "patience = 4\n",
        "best_val_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "num_epochs = 20\n",
        "history = {'accuracy': [], 'val_accuracy': [], 'loss': [], 'val_loss': []}\n",
        "\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    model.train()\n",
        "    running_loss, correct, total = 0.0, 0, 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(inputs)\n",
        "        loss = criterion(logits, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        preds = (torch.sigmoid(logits) >= 0.5).float()\n",
        "        correct += (preds == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100.0 * correct / total\n",
        "\n",
        "    model.eval()\n",
        "    vloss, vcorrect, vtotal = 0.0, 0, 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device).float().unsqueeze(1)\n",
        "            logits = model(inputs)\n",
        "            loss = criterion(logits, labels)\n",
        "            vloss += loss.item()\n",
        "            preds = (torch.sigmoid(logits) >= 0.5).float()\n",
        "            vcorrect += (preds == labels).sum().item()\n",
        "            vtotal += labels.size(0)\n",
        "\n",
        "    val_loss = vloss / len(val_loader)\n",
        "    val_acc = 100.0 * vcorrect / vtotal\n",
        "\n",
        "    history['accuracy'].append(train_acc)\n",
        "    history['val_accuracy'].append(val_acc)\n",
        "    history['loss'].append(train_loss)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "    print(f\"Learning rate now: {current_lr:.6f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        epochs_no_improve = 0\n",
        "        torch.save({'epoch': epoch,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'val_acc': val_acc}, checkpoint_path)\n",
        "        print(f\"Epoch {epoch}: val_acc improved to {val_acc:.2f}%. Saved {checkpoint_path}.\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch} (best val_acc={best_val_acc:.2f}%).\")\n",
        "            break\n",
        "\n",
        "    print(f\"Epoch [{epoch}/{num_epochs}] \"\n",
        "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% \"\n",
        "          f\"| Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
        "\n",
        "print(f\"Training finished. Best Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "# files.download(checkpoint_path)\n"
      ],
      "metadata": {
        "id": "XrO6LJvMmyk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation accuracy and loss\n",
        "\n",
        "acc = history['accuracy']\n",
        "val_acc = history['val_accuracy']\n",
        "loss = history['loss']\n",
        "val_loss = history['val_loss']\n",
        "\n",
        "epochs_range = range(len(acc))\n",
        "\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Train Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training vs Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Train Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training vs Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nN4jXqn2m5L7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test evaluation\n",
        "\n",
        "model.eval()\n",
        "\n",
        "y_true, y_pred, y_prob = [], [], []\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        logits = model(inputs)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs >= 0.5).float()\n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(preds.cpu().numpy().reshape(-1))\n",
        "        y_prob.extend(probs.cpu().numpy().reshape(-1))\n",
        "\n",
        "y_true = np.array(y_true)\n",
        "y_pred = np.array(y_pred)\n",
        "y_prob = np.array(y_prob)\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_true, y_pred, target_names=['NORMAL', 'PNEUMONIA']))\n",
        "\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['NORMAL', 'PNEUMONIA'])\n",
        "disp.plot(cmap='Blues')\n",
        "plt.title('Confusion Matrix'); plt.show()"
      ],
      "metadata": {
        "id": "85kb4doqm9Nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ROC & AUC\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "roc_auc = roc_auc_score(y_true, y_prob)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(fpr, tpr, lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "plt.plot([0,1],[0,1], lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0]); plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve'); plt.legend(loc='lower right'); plt.grid(True)\n",
        "plt.show()\n",
        "print('AUC =', roc_auc)"
      ],
      "metadata": {
        "id": "t5XzHF0UnA5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize misclassified test images\n",
        "\n",
        "mis_idx = np.where(y_true != y_pred)[0]\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "max_show = min(6, len(mis_idx))\n",
        "for i, idx in enumerate(mis_idx[:max_show]):\n",
        "    img_path = test_dataset.samples[idx][0]\n",
        "    img = mpimg.imread(img_path)\n",
        "\n",
        "    plt.subplot(2, 3, i+1)\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    true_label = 'NORMAL' if y_true[idx] == 0 else 'PNEUMONIA'\n",
        "    pred_label = 'NORMAL' if y_pred[idx] == 0 else 'PNEUMONIA'\n",
        "    prob = y_prob[idx]\n",
        "    plt.title(f'True: {true_label}\\nPred: {pred_label} (p={prob:.2f})', color='red')\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9SIVSb6FnEVk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}